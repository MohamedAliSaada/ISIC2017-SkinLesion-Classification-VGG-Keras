# -*- coding: utf-8 -*-
"""data_augment

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TsLUJTSYYZWWJfpN9ii5IyMkJBuwXFJG
"""

!pip install -U tensorflow datasets

from collections import Counter
import os
from tqdm import tqdm
import numpy as np
import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator , load_img , array_to_img , img_to_array

#load data sets from hugging face

from datasets import load_dataset

ds = load_dataset("TynClause/isic-2017-dataset")

#get the train part
ds_train = ds['train']  #{0: 374, 1: 1372, 2: 254}

#make data augmntation to get my data ready

# =======================
#   My Augmentation Goal
# =======================
# For Class 0 → Total 7000 images (374 original + 6626 augmented)
# For Class 1 → Total 7000 images (1372 original + 5628 augmented)
# For Class 2 → Total 7000 images (254 original + 6746 augmented)


# Augmentation setup
data_gen =  ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    brightness_range=(0.9, 1.1),
    horizontal_flip=True,
    fill_mode='nearest'
)


# Output directory where your organized images are saved
out_dir = 'isic-2017'
os.makedirs(out_dir , exist_ok=True)

for example in tqdm(ds_train):
  label = str(example['label'])
  img   = example['image']

  class_dirs =  os.path.join(out_dir , label)
  os.makedirs(class_dirs, exist_ok=True)

  img_path = os.path.join(class_dirs, f"{len(os.listdir(class_dirs))}.jpg")
  img.save(img_path)

print("✅ Original images saved, organized by class.")

# applay my Augmentation setup
import gc # Import garbage collector
target_per_class=7000
augment_per_image=5

for class_name in os.listdir(out_dir):
    class_dir = os.path.join(out_dir, class_name)

    # Sort images numerically to ensure proper order
    images = sorted(os.listdir(class_dir), key=lambda x: int(os.path.splitext(x)[0]))
    num_existing = len(images)
    num_original = len(images)

    next_image_number = num_existing
    num_to_generate = target_per_class - num_existing

    print(f"\nClass {class_name}: {num_original} original, {target_per_class} total, generating {num_to_generate} with batch 5 for each image")

    image_idx = 0
    pbar = tqdm(total=num_to_generate, desc=f'Generating for class {class_name}')

    while num_existing < target_per_class:

        img_path = os.path.join(class_dir, images[image_idx % num_original])
        img = load_img(img_path)
        x = img_to_array(img)
        x = np.expand_dims(x, axis=0)   #pass one img at a time

        aug_iter = data_gen.flow(x, batch_size=augment_per_image) #make from that image 5 aug images

        for _ in range(augment_per_image):
            if num_existing >= target_per_class:
                break

            aug_img = next(aug_iter)[0].astype('uint8')
            save_path = os.path.join(class_dir, f"{next_image_number}.jpg")
            array_to_img(aug_img).save(save_path)

            next_image_number += 1
            num_existing += 1
            pbar.update(1)

        del aug_img, aug_iter, x, img
        gc.collect()

        image_idx += 1

    pbar.close()

print("\n✅ Augmentation complete. 5 augmentations per original, stopped at 7000 images per class.")

